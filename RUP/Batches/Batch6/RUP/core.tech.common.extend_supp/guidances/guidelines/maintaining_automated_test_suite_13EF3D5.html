<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html lang="en" xml:lang="en" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
<head>
<META http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>Guideline: Maintaining Automated Test Suites</title>
<meta name="uma.type" content="Guideline">
<meta name="uma.name" content="maintaining_automated_test_suite">
<meta name="uma.presentationName" content="Maintaining Automated Test Suites">
<meta name="element_type" content="other">
<meta name="filetype" content="description">
<meta name="role" content="none">
<link rel="StyleSheet" href="./../../../css/default.css" type="text/css">
<script src="./../../../scripts/ContentPageResource.js" type="text/javascript" language="JavaScript"></script><script src="./../../../scripts/ContentPageSection.js" type="text/javascript" language="JavaScript"></script><script src="./../../../scripts/ContentPageSubSection.js" type="text/javascript" language="JavaScript"></script><script src="./../../../scripts/ContentPageToolbar.js" type="text/javascript" language="JavaScript"></script><script src="./../../../scripts/contentPage.js" type="text/javascript" language="JavaScript"></script><script type="text/javascript" language="JavaScript">
					var backPath = './../../../';
					var imgPath = './../../../images/';
					var nodeInfo=null;
					contentPage.preload(imgPath, backPath, nodeInfo,  '', false, false, false);
				</script>
</head>
<body>
<div id="breadcrumbs"></div>
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr>
<td valign="top"><a name="Top"></a>
<div id="page-guid" value="_0kF5kMlgEdmt3adZL5Dmdw"></div>
<table border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td class="pageTitle" nowrap="true">Guideline: Maintaining Automated Test Suites</td><td width="100%">
<div align="right" id="contentPageToolbar"></div>
</td><td width="100%" class="expandCollapseLink" align="right"><a name="mainIndex" href="./../../../index.htm"></a><script language="JavaScript" type="text/javascript" src="./../../../scripts/treebrowser.js"></script></td>
</tr>
</table>
<table width="100%" border="0" cellpadding="0" cellspacing="0">
<tr>
<td class="pageTitleSeparator"><img src="./../../../images/shim.gif" alt="" title="" height="1"></td>
</tr>
</table>
<div class="overview">
<table width="97%" border="0" cellspacing="0" cellpadding="0">
<tr>
<td width="50"><img src="./../../../images/guidance.gif" alt="" title=""></td><td>
<table class="overviewTable" border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top">This guideline explains ways to maintain automated test suites - collection of tests performed together for breadth and depth coverage.<p/>Leverage design and management principles that facilitate the maintenance of test suites.</td>
</tr>
</table>
</td>
</tr>
</table>
</div>
<div class="sectionHeading">Relationships</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<th class="sectionTableHeading" scope="row">Related Elements</th><td class="sectionTableCell">
<ul>
<li>
<a href="./../../../core.default.role_def.base/roles/developer_C633AB7.html" guid="_0YDosMlgEdmt3adZL5Dmdw">Developer</a>
</li>
<li>
<a href="./../../../core.tech.common.extend_supp/workproducts/test_script_39A30BA2.html" guid="_0ZfMEMlgEdmt3adZL5Dmdw">Test Script</a>
</li>
</ul>
</td>
</tr>
</table>
</div>
<div class="sectionHeading">Main Description</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td class="sectionTableSingleCell"><h3>
    Introduction
</h3>
<p>
    At some point in your test effort, you may find it necessary to manage your test effort by creating test suites for
    your test assets.&nbsp;Maintaining test suites can take many different forms. To facilitate your testing, you may want
    to introduce some&nbsp;level of&nbsp;automation of your test suites.&nbsp;The fact that you've automated your test
    suites does not necessarily make your testing easier however. It may actually increase the maintenance burden of your
    suites.
</p>
<p>
    This guideline introduces you to useful heuristics on how to facilitate the maintenance of your automated test suites.
</p>
<h4>
    Plan your test&nbsp;suites
</h4>
<p>
    Automating your testing without planning increases&nbsp;the chances that testing will be ineffective
    and&nbsp;inefficient.&nbsp;Some level of planning should take place whether implicit or explicit.&nbsp;An essential
    part of any test plan is the definition of a strategy for test automation.&nbsp;Use your plan to articulate to the
    development team how you plan to maintain your test assets.&nbsp;In many cases, this is never done.&nbsp;The rest of
    the development team may be unaware of how you intend to maintain your tests.&nbsp;It is also a good practice to get
    the rest of the development team to understand that this maintenance can be a substantial part of the overall
    development effort.&nbsp;Use your test tooling to capture this information and treat this plan just like you would
    treat any other test asset in your test repository.
</p>
<h4>
    Centrally locate your test assets
</h4>
<p>
    To facilitate the maintenance of your automated test suites, locate your test assets in a repository that can be
    accessed by the development team.&nbsp;Many test automation environments provide test management tools that make it
    easier to organize and access your test assets by maintaining the test assets (test cases, test scripts, and test
    suites) in a common repository.
</p>
<p>
    In addition, some form of access control is enforced by the automation test tool.&nbsp;This eases the maintenance
    burden by ensuring the integrity of your test suites.&nbsp;You may choose to grant stakeholders and managers read-only
    access, whereas developers and testers at the practitioner level may have read/write access.
</p>
<h4>
    Treat your test assets like any other software
</h4>
<p>
    Software must be maintained.&nbsp;This also applies to the software in your test suites.&nbsp;Test cases and their
    associated test scripts, whether recorded or programmed, should be maintained.&nbsp;And just as software has different
    kinds of maintenance (e.g., corrective, preventative, or adaptive) so too do the assets in your automated test suites.
    As you lifecycle your test suites, identify, if only informally,&nbsp;how&nbsp;you plan to disposition the test suite
    corrective maintenance (e.g., syntactical errors in your scripts),&nbsp;preventative maintenance (e.g., where possible
    to write generalized test scripts), and adaptive maintenance (e.g., how you&nbsp;can use your test tooling to re-assign
    test&nbsp;assets within one suite to&nbsp;another suite or suites).&nbsp;This can be captured, as described in the
    section <strong>Plan Your Test Suites</strong> above, in your test plan.
</p>
<h4>
    Improve the testability of your test suites through collaboration with developers
</h4>
<p>
    It's one thing to say that your test suites will need to be maintained due to changes in the application, changes in
    the testing target, etc.&nbsp;It's quite another thing to actually determine whether a test suite needs to be
    revamped&nbsp;and, if it does, what test assets within it need to be addressed.
</p>
<p>
    One way to facilitate this is to use test suites as a way to communicate test decision to the developers.&nbsp;One way
    to perform continuous perfective maintenance of test suites is to think of your test suites as assets that belong to
    the development team rather than just the testers.&nbsp; You can perform a kind of perfective maintenance on test in
    the following ways:
</p>
<ul>
    <li>
        use test suites to raise the level of abstraction
    </li>
    <li>
        use test suites to provide focus for the developer
    </li>
    <li>
        use test suites to articulate areas that the developers would like testers to focus on
    </li>
    <li>
        make the construction and maintenance&nbsp;of test suites more efficient&nbsp;by understanding what area(s)
        developers want to focus on
    </li>
    <li>
        use test suites to clarify test targets with developers
    </li>
</ul>
<h4>
    Don't be afraid to clean up your suites
</h4>
<p>
    Your test assets will evolve just as the application under test will.&nbsp;As requirements to the system change, the
    application will change as well.&nbsp;To maintain your test suites, you should continually&nbsp;check whether test
    assets are valid.&nbsp;If possible, validity checks should be performed after each new release of the software,
    preferably more frequently.&nbsp;Keeping your test suites relevant is a full-time job.&nbsp;Assume that changes in the
    software will lead to some degree of invalid tests within your test suites.&nbsp;Once these test assets have been
    identified as invalid, get rid of them.&nbsp;This will make the maintenance burden much more tolerable.&nbsp;Some
    automated test tooling environments make this task easier by providing ways to package outdated or invalid
    tests.&nbsp;In some cases, you may not be absolutely sure whether you want to completely get rid of tests within your
    test suite or even of getting rid of test suites altogether.&nbsp; To alleviate this burden, you can create packages
    for obsolete tests or test suites and dispose of tests or test suites by putting them in packages labeled for this
    purpose.
</p><p/><p>
    Like physical objects, tests can break. It's not that they wear down, it's that something's changed in their
    environment. Perhaps they've been ported to a new operating system. Or-more likely-the code they exercise has changed
    in a way that correctly causes the test to fail. Suppose you're working on version 2.0 of an e-banking application. In
    version 1.0, this method was used to log in:
</p>
<p>
    <br />
    <strong>public boolean login (String username);</strong>
</p>
<p>
    <br />
    In version 2.0, the marketing department has realized that password protection might be a good idea. So the method is
    changed to this:
</p>
<p>
    <strong>public boolean login (String username, String password);</strong>
</p>
<p>
    Any test that uses login will fail It won't even compile. Since not much useful work is possible at this point, not
    many useful tests can be written without login. You might be faced with hundreds or thousands of failing tests.
</p>
<p>
    These tests can be fixed by using a global search-and-replace tool that finds every instance of
    login(<em>something</em>) and replaces it with login(<em>something</em>, "dummy password"). Then arrange for all the
    testing accounts to use that password, and you're on your way. Then, when marketing decides that passwords should not
    be allowed to contain spaces, you get to do it all over again. This kind of thing is a wasteful burden, especially
    when-as is often the case-the test changes aren't so easily made. There is a better way.
</p>
<p>
    Suppose that the tests originally did not call the product's login method. Rather, they called a library method that
    does whatever it takes to get the test logged in and ready to proceed. Initially, that method might look like this:
</p>
<p class="codeSample">
    public boolean testLogin (String username) {<br />
    return product.login(username);<br />
    }
</p>
<p>
    When the version 2.0 change happens, the utility library is changed to match:
</p>
<p class="codeSample">
    public Boolean testLogin (String username) {<br />
    return product.login(username, "dummy password");<br />
    }
</p>
<p>
    <br />
    Instead of a changing a thousand tests, you change one method.
</p>
<p>
    Ideally , all the needed library methods would be available at the beginning of the testing effort. In practice, they
    can't all be anticipated-you might not realize you need a testLogin utility method until the first time the product
    login changes. So test utility methods are often "factored out" of existing tests as needed. It is very important that
    you perform this ongoing test repair, even under schedule pressure. If you do not, you will waste much time dealing
    with an ugly and un-maintainable test suite. You might well find yourself throwing it away, or being unable to write
    the needed numbers of new tests because all your available testing time is spent maintaining old ones.
</p>
<p>
    <br />
    <strong>Note</strong>: the tests of the product's login method will still call it directly. If its behavior changes,
    some or all of those tests will need to be updated. (If none of the login tests fail when its behavior changes, they're
    probably not very good at detecting defects.)
</p>
<p>
    <br />
    <strong>Another example</strong><br />
    Suppose you're testing a compiler. Some of the first classes written define the compiler's internal parse tree and the
    transformations made upon it. You have a number of tests that construct parse trees and test the transformations. One
    such test might look like this:
</p>
<p class="codeSample">
	<!-- START NON-TRANSLATABLE -->
    /*<br />
    * Given<br />
    * while (i&lt;0) { f(a+i); i++;}<br />
    * "a+i" cannot be hoisted from the loop because<br />
    * it contains a variable changed in the loop.<br />
    */<br />
    loopTest = new LessOp(new Token("i"), new Token("0"));<br />
    aPlusI = new PlusOp(new Token("a"), new Token("i"));<br />
    statement1 = new Statement(new Funcall(new Token("f"), aPlusI));<br />
    statement2 = new Statement(new PostIncr(new Token("i"));<br />
    loop = new While(loopTest, new Block(statement1, statement2));<br />
    expect(false, loop.canHoist(aPlusI))
	<!-- END NON-TRANSLATABLE -->
</p>
<p>
    <br />
    This is a difficult test to read. Suppose that time passes. Something changes that requires you to update the tests. At
    this point, you have more product infrastructure to draw upon. In particular, you might have a parsing routine that
    turns strings into parse trees. It would be better at this point to completely rewrite the tests to use it:
</p>
<p>
    loop=Parser.parse("while (i&lt;0) { f(a+i); i++; }");<br />
    // Get a pointer to the "a+i" part of the loop.<br />
    aPlusI = loop.body.statements[0].args[0];<br />
    expect(false, loop.canHoist(aPlusI));
</p>
<p>
    Such tests will be much easier to understand, which will save time immediately and in the future. In fact, their
    maintenance costs are so much lower that it might make sense to defer most of them until the parser is available.
</p>
<p>
    There's a slight downside to this approach: such tests might discover a defect in either the transformation code (as
    intended) or in the parser (by accident). So problem isolation and debugging may be somewhat more difficult. On the
    other hand, finding a problem that the parser tests miss isn't such a bad thing.<br />
    There is also a chance that a defect in the parser might mask a defect in the transformation code. The chance of this
    is rather small, and the cost from it is almost certainly less than the cost of maintaining the more complicated tests.
</p>
<p>
    <strong>Focusing test improvement</strong><br />
    A large test suite will contain some blocks of tests that don't change. They correspond to stable areas in the
    application. Other blocks of tests will change often. They correspond to areas in the application where behavior is
    changing often. These latter blocks of test will tend to make heavier use of utility libraries. Each test will test
    specific behaviors in the changeable area. The utility libraries are designed to allow such a test to check its
    targeted behaviors while remaining relatively immune to changes in untested behaviors.
</p>
<p>
    For example, the "loop hoisting" test shown above is now immune to the details of how parse trees are built. It is
    still sensitive to the structure of a while loop's parse tree (because of the sequences of accesses required to fetch
    the sub-tree for a+i). If that structure proves changeable, the test can be made more abstract by creating a
    fetchSubtree utility method:
</p>
<p class="codeSample">
    loop=Parser.parse("while (i&lt;0) { f(a+i); i++; }");<br />
    aPlusI = fetchSubtree(loop, "a+i");<br />
    expect(false, loop.canHoist(aPlusI));
</p>
<p>
    The test is now sensitive only to two things: the definition of the language (for example, that integers can be
    incremented with ++), and the rules governing loop hoisting (the behavior whose correctness it's checking).
</p>
<p>
    <br />
    <strong>Throwing away tests</strong><br />
    Even with utility libraries, a test might periodically be broken by behavior changes that have nothing to do with what
    it checks. Fixing the test doesn't stand much of a chance of finding a defect due to the change; it's something you do
    to preserve the test's chance of finding some other defect someday. But the cost of such a series of fixes might exceed
    the value of the test's hypothetically finding a defect. It might be better to simply throw the test away and devote
    the effort to creating new tests with greater value.<br />
    Most people resist the notion of throwing away a test-at least until they're so overwhelmed by the maintenance burden
    that they throw all the tests away. It is better to make the decision carefully and continuously, test by test, asking:
</p>
<p>
    <br />
    1. How much work will it be to fix this test well, perhaps adding to the utility library?<br />
    2. How else might the time be used?<br />
    3. How likely is it that the test will find serious defects in the future? What's been the track record of it and
    related tests?<br />
    4. How long will it be before the test breaks again?
</p>
<p>
    <br />
    The answers to these questions will be rough estimates or even guesses. But asking them will yield better results than
    simply having a policy of fixing all tests.
</p>
<p>
    <br />
    Another reason to throw away tests is that they've become redundant. For example, early in development, there might be
    a multitude of simple tests of basic parse-tree construction methods (the LessOp constructor and the like). Later,
    during the writing of the parser, there will be a number of parser tests. Since the parser uses the construction
    methods, the parser tests will also indirectly test them. As code changes break the construction tests, it's reasonable
    to discard some of them as being redundant. Of course, any new or changed construction behavior will need new tests.
    They might be implemented directly (if they're hard to test thoroughly through the parser) or indirectly (if tests
    through the parser are adequate and more maintainable).<br />
    <br />
</p></td>
</tr>
</table>
</div>
<table class="copyright" border="0" cellspacing="0" cellpadding="0">
<tr>
<td class="copyright"><p>
    This program and the accompanying materials are made available under the<br />
    <a href="http://www.eclipse.org/org/documents/epl-v10.php" target="_blank">Eclipse Public License V1.0</a>, which
    accompanies this distribution.
</p>
<p>
    <a class="elementLink" href="./../../../core.default.release_copyright.base/guidances/supportingmaterials/epf_copyright_C3031062.html" guid="_UaGfECcTEduSX6N2jUafGA">EPF Copyright</a>.
</p><p/><p>
    Licensed Materials - Property of IBM<br />
    &copy; &nbsp;Copyright IBM Corp.&nbsp;1987, 2011.&nbsp; All Rights Reserved.
</p></td>
</tr>
</table>
</td>
</tr>
</table>
</body>
<script type="text/javascript" language="JavaScript">
				contentPage.onload();
			</script>
</html>
