<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html lang="en" xml:lang="en" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
<head>
<META http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>Concept: Test-Ideas List</title>
<meta name="uma.type" content="Concept">
<meta name="uma.name" content="test_ideas_list">
<meta name="uma.presentationName" content="Test-Ideas List">
<meta name="element_type" content="concept">
<meta name="filetype" content="description">
<meta name="role" content="none">
<link rel="StyleSheet" href="./../../../css/default.css" type="text/css">
<script src="./../../../scripts/ContentPageResource.js" type="text/javascript" language="JavaScript"></script><script src="./../../../scripts/ContentPageSection.js" type="text/javascript" language="JavaScript"></script><script src="./../../../scripts/ContentPageSubSection.js" type="text/javascript" language="JavaScript"></script><script src="./../../../scripts/ContentPageToolbar.js" type="text/javascript" language="JavaScript"></script><script src="./../../../scripts/contentPage.js" type="text/javascript" language="JavaScript"></script><script type="text/javascript" language="JavaScript">
					var backPath = './../../../';
					var imgPath = './../../../images/';
					var nodeInfo=null;
					contentPage.preload(imgPath, backPath, nodeInfo,  '', false, false, false);
				</script>
</head>
<body>
<div id="breadcrumbs"></div>
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr>
<td valign="top"><a name="Top"></a>
<div id="page-guid" value="_othWcHHSEdyzS55ez-koKA"></div>
<table border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td class="pageTitle" nowrap="true">Concept: Test-Ideas List</td><td width="100%">
<div align="right" id="contentPageToolbar"></div>
</td><td width="100%" class="expandCollapseLink" align="right"><a name="mainIndex" href="./../../../index.htm"></a><script language="JavaScript" type="text/javascript" src="./../../../scripts/treebrowser.js"></script></td>
</tr>
</table>
<table width="100%" border="0" cellpadding="0" cellspacing="0">
<tr>
<td class="pageTitleSeparator"><img src="./../../../images/shim.gif" alt="" title="" height="1"></td>
</tr>
</table>
<div class="overview">
<table width="97%" border="0" cellspacing="0" cellpadding="0">
<tr>
<td width="50"><img src="./../../../images/concept.gif" alt="" title=""></td><td>
<table class="overviewTable" border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top">A test idea list is a list of test ideas sorted in decreasing order of importance and associated with specific testing strategies used to create executable tests.</td>
</tr>
</table>
</td>
</tr>
</table>
</div>
<div class="sectionHeading">Relationships</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<th class="sectionTableHeading" scope="row">Related Elements</th><td class="sectionTableCell">
<ul>
<li>
<a href="./../../../practice.tech.independent_testing.base-ibm/tasks/create_test_cases_765DDFED.html" guid="_ywvLQHE3Edy8Ac588DXPCQ">Develop Test Cases</a>
</li>
<li>
<a href="./../../../practice.tech.independent_testing.base-ibm/tasks/identify_test_ideas_D97DA26C.html" guid="_eS9qEHE4Edy8Ac588DXPCQ">Identify Test Ideas</a>
</li>
<li>
<a href="./../../../core.tech.common.extend_supp-ibm/workproducts/test_ideas_list_195666E2.html" guid="_7ukFEHE7Edy8Ac588DXPCQ">Test Ideas List</a>
</li>
</ul>
</td>
</tr>
</table>
</div>
<div class="sectionHeading">Main Description</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td class="sectionTableSingleCell"><h3>
    <a id="Introduction" name="Introduction">Introduction</a>
</h3>
<p>
    Information used in designing tests is gathered from many places: design models, classifier interfaces, statecharts,
    and code itself. At some point, this source document information must be transformed into executable tests:
</p>
<ul>
    <li>
        specific inputs given to the software under test
    </li>
    <li>
        a particular hardware and software configuration
    </li>
    <li>
        initialized to a known state
    </li>
    <li>
        specific results expected
    </li>
</ul>
<p>
    It's possible to go directly from source document information to executable tests, but it's often useful to add an
    intermediate step. In this step,<em>&nbsp;<a class="elementLinkWithUserText" href="./../../../core.tech.common.extend-ibm/guidances/termdefinitions/test_idea_C3E60830.html" guid="_ru5GwLSvEdyPwbrU35sd4A">test ideas</a></em> are written into a <i>Test-Ideas List</i>, which is used to create
    executable tests.
</p>
<h3>
    <a id="TestIdeas" name="TestIdeas">What are Test Ideas?</a>
</h3>
<p>
    A test idea (sometimes referred to as a <a class="elementLink" href="./../../../core.tech.common.extend-ibm/guidances/termdefinitions/test_requirement_D46BA4A3.html" guid="_2k18oLSvEdyPwbrU35sd4A">test requirement</a>) is a brief statement about a test that could be performed. As a
    simple example, let's consider a function that calculates a square root and come up with some test ideas:
</p>
<ul>
    <li>
        give a number that's barely less than zero as input
    </li>
    <li>
        give zero as the input
    </li>
    <li>
        test a number that's a perfect square, like 4 or 16 (is the result exactly 2 or 4?)
    </li>
</ul>
<p>
    Each of these ideas could readily be converted into an executable test with exact descriptions of inputs and expected
    results.
</p>
<p>
    There are two advantages to this less-specific intermediate form:
</p>
<ul>
    <li>
        test ideas are more reviewable and understandable than complete tests-it's easier to understand the reasoning
        behind them
    </li>
    <li>
        test ideas support more powerful tests, as described later
    </li>
</ul>
<p>
    The square root examples all describe inputs, but test ideas can describe any of the elements of an executable test.
    For example, "print to a LaserJet IIIp" describes an aspect of the&nbsp;<a class="elementLink" href="./../../../core.tech.common.extend-ibm/guidances/termdefinitions/test_environment_1304DF1F.html" guid="_ouDPILSzEdyPwbrU35sd4A">test environment</a> to be used for a test, as does "test with database full", however,
    these latter test ideas are very incomplete in themselves: Print <b>what</b> to the printer? Do <b>what</b> with that
    full database? They do, however, ensure that important ideas aren't forgotten; ideas that will be described in more
    detail later in test design.
</p>
<p>
    Test ideas are often based on <a class="elementLinkWithUserText" href="./../../../core.tech.common.extend-ibm/guidances/termdefinitions/fault_model_32142724.html" guid="_YjUF4LSzEdyPwbrU35sd4A">fault models</a>; notions of which faults are plausible in software and how those faults
    can best be uncovered. For example, consider boundaries. It's safe to assume the square root function can be
    implemented something like this:
</p>
<blockquote>
<pre>
double sqrt(double x) {
if (x &lt; 0) 
// signal error
...
</pre>
</blockquote>
<p>
    It's also plausible that the <b>&lt;</b> will be incorrectly typed as <b>&lt;=</b>. People often make that kind of
    mistake, so it's worth checking. The fault cannot be detected with <b>X</b> having the value <b>2</b>, because both the
    incorrect expression (<b>x&lt;=0</b>) and the correct expression (<b>x&lt;0</b>) will take the same branch of the
    <b>if</b> statement. Similarly, giving <b>X</b> the value -<b>5</b> cannot find the fault. The only way to find it is
    to give <b>X</b> the value <b>0</b>, which justifies the second test idea.
</p>
<p>
    In this case, the fault model is explicit. In other cases, it's implicit. For example, whenever a program manipulates a
    linked structure, it's good to test it against a circular one. It's possible that many faults could lead to a
    mishandled circular structure. For the purposes of testing, they needn't be enumerated-it suffices to know that some
    fault is likely enough that the test is worth running.
</p>
<p>
    These fault models can be applied to many different work products. For example, the first one describes what to do with
    Boolean expressions. Such expressions can be found in code, in guard conditions, in statecharts and sequence diagrams,
    and in natural-language descriptions of method behaviors (such as you might find in a published API).
</p>
<p>
    Occasionally it's also helpful to have guidelines for specific work products.
</p>
<p>
    A particular Test-Ideas List might contain test ideas from many fault models, and those fault models could be derived
    from more than one work product.
</p>
<h3>
    <a id="TestDesignUsingTheList" name="TestDesignUsingTheList">Test Design Using the List</a>
</h3>
<p>
    Let's suppose you're designing tests for a method that searches for a string in a sequential collection. It can either
    obey case or ignore case in its search, and it returns the index of the first match found or -1 if no match is found.
</p>
<blockquote>
<pre>
int Collection.find(String string,
Boolean ignoreCase);
</pre>
</blockquote>
<p>
    Here are some test ideas for this method:
</p>
<ol>
    <li>
        match found in the first position
    </li>
    <li>
        match found in the last position
    </li>
    <li>
        no match found
    </li>
    <li>
        two or more matches found in the collection
    </li>
    <li>
        case is ignored; match found, but it wouldn't match if case was obeyed
    </li>
    <li>
        case is obeyed; an exact match is found
    </li>
    <li>
        case is obeyed; a string that would have matched if case were ignored is skipped
    </li>
</ol>
<p>
    It would be simple to implement these seven tests, one for each test idea. However, different test ideas can be
    combined into a single test. For example, the following test <i>satisfies</i> test ideas 2, 6, and 7:
</p>
<blockquote>
    <p>
        Setup: collection initialized to ["dawn", "Dawn"]<br />
        Invocation: collection.find("Dawn", false)<br />
        Expected result: return value is 1 (it would be 0 if "dawn" were not skipped)
    </p>
</blockquote>
<p>
    Making test ideas nonspecific makes them easier to combine.
</p>
<p>
    It's possible to satisfy all of the test ideas in three tests. Why would three tests that satisfy seven test ideas be
    better than seven separate tests?
</p>
<ul>
    <li>
        When you're creating a large number of simple tests, it's common to create test N+1 by copying test N and tweaking
        it just enough to satisfy the new test idea. The result, especially in more complex software, is that test N+1
        probably exercises the program in almost the same way as test N. It takes almost exactly the same path through the
        code.<br />
        <br />
        A smaller number of tests, each satisfying several test ideas, doesn't allow a "copy and tweak" approach. Each test
        will be somewhat different from the last, exercising the code in different ways and taking different paths.<br />
        <br />
        Why would that be better? If the Test-Ideas List were complete, with a test idea for every fault in the program, it
        wouldn't matter how you wrote the tests. But the list is always missing some test ideas that could find bugs. By
        having each test do very different things from the last one-by adding seemingly unneeded variety-you increase the
        chance that one of the tests will stumble over a bug by sheer dumb luck. In effect, smaller, more complex tests
        increase the chance the test will satisfy a test idea that you didn't know you needed.<br />
        <br />
    </li>
    <li>
        Sometimes when you're creating more complex tests, new test ideas come to mind. That happens less often with simple
        tests, because so much of what you're doing is exactly like the last test, which dulls your mind.
    </li>
</ul>
<p>
    However, there are reasons for not creating complex tests.
</p>
<ul>
    <li>
        If each test satisfies a single test idea and the test for idea 2 fails, you immediately know the most likely
        cause: the program doesn't handle a match in the last position. If a test satisfies ideas 2, 6, and 7, then
        isolating the failure is harder.<br />
        <br />
    </li>
    <li>
        Complex tests are more difficult to understand and maintain. The intent of the test is less obvious.<br />
        <br />
    </li>
    <li>
        Complex tests are more difficult to create. Constructing a test that satisfies five test ideas often takes more
        time than constructing five tests that each satisfy one. Moreover, it's easier to make mistakes-to think you're
        satisfying all five when you're only satisfying four.
    </li>
</ul>
<p>
    In practice, you must find a reasonable balance between complexity and simplicity. For example, the first tests you
    subject the software to (typically the <a class="elementLinkWithUserText" href="./../../../core.tech.common.extend-ibm/guidances/termdefinitions/smoke_test_35E20F16.html" guid="_Jk5wYLS0EdyPwbrU35sd4A">smoke tests</a>) should be simple, easy to understand and maintain, and intended to
    catch the most obvious problems. Later tests should be more complex, but not so complex they are not maintainable.
</p>
<p>
    After you've finished a set of tests, it's good to check them against the characteristic test design mistakes.
</p>
<h3>
    <a id="UsingTestIdeasBeforeTest" name="UsingTestIdeasBeforeTest">Using Test Ideas Before Testing</a>
</h3>
<p>
    A Test-Ideas List is useful for reviews and inspections of design work products. For example, consider this part of
    a&nbsp;design model&nbsp;showing the association between Department and Employee classes.
</p>
<p align="center">
    <img height="45" alt="Design Model Example Image" src="./../../../core.tech.common.extend_supp-ibm/guidances/concepts/./resources/tstidslst-img1.gif" width="223" />
</p>
<p class="picturetext">
    Figure 1: Association between Department and Employee Classes
</p>
<p>
    The rules for creating test ideas from such a model would ask you to consider the case where a department has many
    employees. By walking through a design and asking "what if, at this point, the department has many employees?", you
    might discover design or analysis errors. For example, you might realize that only one employee at a time can be
    transferred between departments. That might be a problem if the corporation is prone to sweeping reorganizations where
    many employees need to be transferred.
</p>
<p>
    Such faults, cases where a possibility was overlooked, are called <i>faults of omission</i>. Just like the faults
    themselves, you have probably omitted tests that detect these faults from your testing effort. For example, see
    [GLA81], [OST84], [BAS87], [MAR00], and other studies that show how often faults of omission escape into
    deployment.&nbsp;&nbsp;
</p>
<h3>
    <a id="TestIdeasTraceability" name="TestIdeasTraceability">Test Ideas and Traceability</a>
</h3>
<p>
    Traceability&nbsp;is a matter of tradeoffs. Is its value worth the cost of maintaining it?
</p>
<p>
    When traceability is worthwhile, it's conventional to trace tests back to the work products that inspired them. For
    example, you might have traceability between an API and its tests. If the API changes, you know which tests to change.
    If the code (that implements the API) changes, you know which tests to run. If a test puzzles you, you can find the API
    it's intended to test.
</p>
<p>
    The Test-Ideas List adds another level of traceability. You can trace from a test to the test ideas it satisfies, and
    then from the test ideas to the original work product.
</p>
<h3>
    References
</h3>
<ul>
    <li>
        GLA81&nbsp;&nbsp; Robert L. Glass 1981. <i>Persistent Software Errors.</i> IEEE Transactions on Software
        Engineering, March 1981.
    </li>
    <li>
        OST84&nbsp;&nbsp;&nbsp;Thomas J. Ostrand and Elaine J. Weyuker 1984. <i>Collecting and Categorizing Software Error
        Data in an Industrial Environment.</i> Journal of Systems and Software, Vol. 4, 1984.
    </li>
    <li>
        BAS87&nbsp;&nbsp; BAS87 Victor R. Basili and H. Dieter Rombach 1987. <i>Tailoring the Software Process to Project
        Goals and Environments.</i> Proceedings of the 9th International Conference on Software Engineering Software, IEEE
        Press.
    </li>
    <li>
        MAR00&nbsp;&nbsp; Brian Marick 2000. <i>Faults of Omission.</i> Software Testing and Quality Engineering Magazine,
        March-April 2000.<br />
        <br />
    </li>
</ul></td>
</tr>
</table>
</div>
<table class="copyright" border="0" cellspacing="0" cellpadding="0">
<tr>
<td class="copyright"><p>
    Licensed Materials - Property of IBM<br />
    &copy; &nbsp;Copyright IBM Corp.&nbsp;1987, 2011.&nbsp; All Rights Reserved.
</p></td>
</tr>
</table>
</td>
</tr>
</table>
</body>
<script type="text/javascript" language="JavaScript">
				contentPage.onload();
			</script>
</html>
