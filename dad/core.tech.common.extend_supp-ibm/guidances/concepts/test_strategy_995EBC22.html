<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html lang="en" xml:lang="en" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
<head>
<META http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>Concept: Test Strategy</title>
<meta name="uma.type" content="Concept">
<meta name="uma.name" content="test_strategy">
<meta name="uma.presentationName" content="Test Strategy">
<meta name="element_type" content="concept">
<meta name="filetype" content="description">
<meta name="role" content="none">
<link rel="StyleSheet" href="./../../../css/default.css" type="text/css">
<script src="./../../../scripts/ContentPageResource.js" type="text/javascript" language="JavaScript"></script><script src="./../../../scripts/ContentPageSection.js" type="text/javascript" language="JavaScript"></script><script src="./../../../scripts/ContentPageSubSection.js" type="text/javascript" language="JavaScript"></script><script src="./../../../scripts/ContentPageToolbar.js" type="text/javascript" language="JavaScript"></script><script src="./../../../scripts/contentPage.js" type="text/javascript" language="JavaScript"></script><script type="text/javascript" language="JavaScript">
					var backPath = './../../../';
					var imgPath = './../../../images/';
					var nodeInfo=null;
					contentPage.preload(imgPath, backPath, nodeInfo,  '', false, false, false);
				</script>
</head>
<body>
<div id="breadcrumbs"></div>
<table border="0" cellpadding="0" cellspacing="0" width="100%">
<tr>
<td valign="top"><a name="Top"></a>
<div id="page-guid" value="_87RzwHHTEdyzS55ez-koKA"></div>
<table border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td class="pageTitle" nowrap="true">Concept: Test Strategy</td><td width="100%">
<div align="right" id="contentPageToolbar"></div>
</td><td width="100%" class="expandCollapseLink" align="right"><a name="mainIndex" href="./../../../index.htm"></a><script language="JavaScript" type="text/javascript" src="./../../../scripts/treebrowser.js"></script></td>
</tr>
</table>
<table width="100%" border="0" cellpadding="0" cellspacing="0">
<tr>
<td class="pageTitleSeparator"><img src="./../../../images/shim.gif" alt="" title="" height="1"></td>
</tr>
</table>
<div class="overview">
<table width="97%" border="0" cellspacing="0" cellpadding="0">
<tr>
<td width="50"><img src="./../../../images/concept.gif" alt="" title=""></td><td>
<table class="overviewTable" border="0" cellspacing="0" cellpadding="0">
<tr>
<td valign="top">This guideline discusses how to develop a Test Strategy whose purpose is to describe the general approach and objectives of the test tasks.</td>
</tr>
</table>
</td>
</tr>
</table>
</div>
<div class="sectionHeading">Main Description</div>
<div class="sectionContent">
<table class="sectionTable" border="0" cellspacing="0" cellpadding="0">
<tr valign="top">
<td class="sectionTableSingleCell"><p>
    A strategy for the testing portion of a project describes the general approach and objectives of the test tasks. It
    includes those stages of testing (unit, integration, and system) to be addressed and the kinds of testing (function,
    performance, load, stress) to be performed.
</p>
<p>
    The strategy defines:
</p>
<ul>
    <li>
        Testing techniques and tools to be used.
    </li>
    <li>
        What test completion and success criteria will be used. For example, the criteria might allow the software to
        progress to acceptance testing when 95% of the test cases have been successfully executed. Another criterion is
        code coverage. This criterion may, in a safety-critical system, be that 100% of the code should be covered by
        tests.
    </li>
    <li>
        Special considerations affect resource requirements or have schedule implications such as:
    </li>
</ul>
<div style="MARGIN-LEFT: 2em">
    <ul>
        <li>
            testing all interfaces to external systems
        </li>
        <li>
            simulating physical damage or security threat
        </li>
    </ul>
</div>
<p>
    Some organizations have defined corporate test strategies, in which case you work to apply those strategies to your
    specific project.
</p>
<p>
    The most important dimensions around which you should plan your test tasks are:
</p>
<ul>
    <li>
        What iteration you are you in and what are the goals of that iteration?
    </li>
    <li>
        What stage of test (unit test, integration test, system test) are you are performing? You might work all stages of
        test in one iteration.
    </li>
</ul>
<p>
    Now take a look at how the characteristics of your test tasks can change depending on where you are in the previously
    mentioned test dimensions. There are many characteristics you could look at, such as resources needed and time spent,
    but, at this point, focus on what is important to defining your test strategy such as:
</p>
<ul>
    <li>
        types of test (functional, stress, volume, performance, usability, distribution, and so on)
    </li>
    <li>
        evaluation criteria used (code-based test coverage, requirements-based test coverage, number of defects,
        mean-time-between-failure, and so on)
    </li>
    <li>
        testing techniques used (manual and automated)
    </li>
</ul>
<p>
    There is no general pattern for how the types of tests are distributed over the test cycles. You focus on different
    types of tests depending on the number of iterations, the size of the iteration, and what kind of project this is that
    you're testing.
</p>
<p>
    You will find that the system test stage has a strong focus on making sure you are covering all testable requirements
    expressed in terms of a set of test cases. This means your completion criteria will focus on requirements-based test
    coverage. In the integration and unit test stages, you will find code-based test coverage is a more appropriate
    completion criterion. The next figure shows how the use of these two types of test coverage measures can change as you
    develop new iterations of your software.
</p>
<ul>
    <li>
        The test plan should define sets of completion criteria for unit test, integration test, and system test.
    </li>
    <li>
        You may have different sets of completion criteria defined for individual iterations.
    </li>
</ul>
<p align="center">
    <img height="183" alt="Requirements and Code Based Areas of a Test Table Image" src="./../../../core.tech.common.extend_supp-ibm/guidances/concepts/./resources/testr001.gif"     width="307" />
</p>
<p>
    On your project, consider automating your tests as much as possible, specifically the kind of tests you repeat several
    times (regression tests). Keep in mind that it costs time and resources to create and maintain automated tests. There
    will always be some amount of manual testing on each project. The following figure illustrates when and in what stages
    of testing you'll probably perform manual tests.
</p>
<p align="center">
    <img height="183" alt="Test Table with Manual Test Areas Circled Image" src="./../../../core.tech.common.extend_supp-ibm/guidances/concepts/./resources/testr002.gif" width="307" />
</p>
<p>
    <b>Example</b>
</p>
<p>
    The following tables show when the different types of tests are identified and provide an example of the completion
    criteria to define. The first table shows a "typical" MIS project.
</p>
<div align="center">
    <table     style="BORDER-RIGHT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-BOTTOM: rgb(128,128,128) 1px solid"      cellspacing="0" bordercolordark="#808080" cellpadding="4" width="85%" bordercolorlight="#808080" border="1">
        <tbody>
            <tr>
                <th width="9%">
                    <b>Iteration test</b>
                </th>
                <th width="45%">
                    <b>System test</b>
                </th>
                <th width="28%">
                    <b>Integration test</b>
                </th>
                <th width="18%">
                    <b>Unit test</b>
                </th>
            </tr>
            <tr>
                <td width="9%">
                    Iteration 1
                </td>
                <td width="45%">
                    Automated performance testing for all use cases.<br />
                     · All planned tests have been executed.<br />
                     · All severity 1 defects have been addressed.<br />
                     · All planned tests have been re-executed and no new severity 1 defects have been identified.
                </td>
                <td width="28%">
                    None
                </td>
                <td width="18%">
                    Informal testing
                </td>
            </tr>
            <tr>
                <td width="9%">
                    Iteration 2
                </td>
                <td width="45%">
                    Automated performance and functionality testing for all new use cases and the previous as regression
                    test.<br />
                     · All planned tests have been executed.<br />
                     · All severity 1 and 2 defects have been addressed.<br />
                     · All planned tests have been re-executed and no new severity 1 or 2 defects have been identified.
                </td>
                <td width="28%">
                    None
                </td>
                <td width="18%">
                    Informal testing
                </td>
            </tr>
            <tr>
                <td width="9%">
                    Iteration 3
                </td>
                <td width="45%">
                    Automated functionality and negative testing for all new use cases, and all the previous as regression
                    test; 95% of test cases have to pass.<br />
                     · All planned tests have been executed.<br />
                     · All severity 1, 2, and 3 defects identified.
                </td>
                <td width="28%">
                    Automated testing, 70% code coverage.
                </td>
                <td width="18%">
                    Informal testing
                </td>
            </tr>
            <tr>
                <td width="9%">
                    Iteration 4
                </td>
                <td width="45%">
                    Automated functionality and negative testing for all use cases, manual testing for all parts that are
                    not automated, and all the previous as regression test. 100% of test cases have to pass.<br />
                     · All planned tests have been executed.<br />
                     · All severity 1, 2, and 3 defects have been addressed.<br />
                     · All planned tests have been re-executed and no new severity 1 or 2 defects have been identified.
                </td>
                <td width="28%">
                    Automated testing, 80% code coverage.
                </td>
                <td width="18%">
                    Informal testing
                </td>
            </tr>
        </tbody>
    </table><br />
</div>
<p>
    The second table shows the types of test and completion criteria applied for a <i>typical</i> safety-critical system.
</p>
<div align="center">
    <table     style="BORDER-RIGHT: rgb(128,128,128) 1px solid; BORDER-TOP: rgb(128,128,128) 1px solid; BORDER-LEFT: rgb(128,128,128) 1px solid; BORDER-BOTTOM: rgb(128,128,128) 1px solid"      cellspacing="0" bordercolordark="#808080" cellpadding="4" width="85%" bordercolorlight="#808080" border="1">
        <tbody>
            <tr>
                <th width="9%">
                    <b>Iteration test</b>
                </th>
                <th width="45%">
                    <b>System test</b>
                </th>
                <th width="28%">
                    <b>Integration test</b>
                </th>
                <th width="18%">
                    <b>Unit test</b>
                </th>
            </tr>
            <tr>
                <td>
                    Iteration 1
                </td>
                <td>
                    Automated performance testing for all use cases; 100% test-case coverage.<br />
                     · All planned tests have been executed.<br />
                     · All severity 1 defects have been addressed.<br />
                     · All planned tests have been re-executed and no new defects have been identified.
                </td>
                <td>
                    None
                </td>
                <td>
                    None
                </td>
            </tr>
            <tr>
                <td>
                    Iteration 2
                </td>
                <td>
                    Automated performance, functionality, and negative testing for all use cases; 100% test-case
                    coverage.<br />
                     · All planned tests have been executed.<br />
                     · All severity 1 or 2 defects have been addressed.<br />
                     · All planned tests have been re-executed and no new defects have been identified.
                </td>
                <td>
                    Automated performance testing
                </td>
                <td>
                    Informal testing
                </td>
            </tr>
            <tr>
                <td>
                    Iteration 3
                </td>
                <td>
                    Automated performance, functionality, negative usability, and documentation testing for all use cases;
                    100% test-case coverage.<br />
                     · All planned tests have been executed.<br />
                     · All severity 1, 2, and 3 defects have been addressed.<br />
                     · All planned tests have been re-executed and no new defects have been identified.
                </td>
                <td>
                    Automated performance testing and the previous as regression test
                </td>
                <td>
                    Automated testing, 70% code coverage
                </td>
            </tr>
            <tr>
                <td>
                    Iteration 4
                </td>
                <td>
                    Automated performance, functionality, negative usability, and documentation testing for all use cases;
                    100% test-case coverage.<br />
                     · All planned tests have been executed.<br />
                     · All severity 1, 2, and 3 defects have been addressed.<br />
                     · All planned tests have been re-executed and no defects have been identified.
                </td>
                <td>
                    Automated performance testing and the previous as regression testing
                </td>
                <td>
                    Automated testing, 80% code coverage
                </td>
            </tr>
        </tbody>
    </table>
</div><br />
<br /></td>
</tr>
</table>
</div>
<table class="copyright" border="0" cellspacing="0" cellpadding="0">
<tr>
<td class="copyright"><p>
    Licensed Materials - Property of IBM<br />
    &copy; &nbsp;Copyright IBM Corp.&nbsp;1987, 2011.&nbsp; All Rights Reserved.
</p></td>
</tr>
</table>
</td>
</tr>
</table>
</body>
<script type="text/javascript" language="JavaScript">
				contentPage.onload();
			</script>
</html>
